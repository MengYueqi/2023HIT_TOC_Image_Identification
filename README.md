# 2023HIT_TOC_Image_Identification
2023HIT计算理论课设，完成不同方法完成图像的识别，并比较图像识别的效果。

## 数据集准备
使用数据集：https://www.kaggle.com/datasets/julichitai/multilabel-small-car-and-color-dataset 数据集中图片以裁切好。数据集中的文件结构如下：
``` 
.
├── matiz black
├── matiz blue
├── matiz red
├── rio black
├── rio blue
├── rio red
├── tiggo black
├── tiggo blue
└── tiggo red
``` 
数据集一共有9个类，使用不同的模型对以上图片进行分类，并对分类结果进行分析。

## 传统方法进行识别
在深度学习出现之前，有很多传统方法完成图像的识别，这些方法有着不错的准确度。使用一些传统方法进行识别，并分析其中识别的原理，比较不同模型的差别。

> 有很多识别图像的传统方法，负责这部分的同学可以在支持向量机、层次聚类、马尔可夫随机场、随机森林、AdaBoost等方法内选择两个方法进行撰写(当然如果有更好的也可以)。模型写完后分析一下模型的优缺点和识别失败的图像的原因。将分析的内容写在readme文件中，画的图和相关的代码直接在仓库中建一个文件夹push上去即可。

## Hierarchical Clustering(层次聚类)
层次聚类是一种数据挖掘和机器学习技术，它根据图像之间的相似特性将它们分组。聚类是一种无监督学习方法，它基于图像之间的相似性将图像分为簇或组。因此，准确度是固定的，并且不会单独生成准确度图。

上述代码使用层次聚合聚类（Hierarchical Agglomerative Clustering）对图像数据进行聚类，并生成了一个表示结果的树状图（Dendrogram）。

<img width="1344" alt="스크린샷 2023-11-08 오전 9 11 14" src="https://github.com/MengYueqi/2023HIT_TOC_Image_Identification/assets/148426243/dc9d09f0-223d-4775-85c7-3b1e3d1ce0e5">

树状图的纵轴代表相似性，横轴代表聚集在一起的节点数（图像数）。

树结构：树状图以树的形式展现。这棵树从所有图像数据点开始，表示按层次合并的聚类过程。在最底层是单个图像，向上移动到更高的层次时，图像逐渐合并成簇。

分支（Branch）和节点（Node）：树的分支代表图像或簇，节点代表分支合并的地方。在节点合并分支时，该节点的高度对应的距离信息会被表示出来。

高度（Height）：每个节点处分支合并到该点的高度表示聚类的相似性。高度越低，说明相应的簇彼此间具有更相似的特征，高度越高，则表示具有不同特征的簇合并在一起。

树分支的长度：树分支的长度表示两个簇合并时的距离（相似性或不相似性）。分支越长，表示合并的簇具有更不同的特征，分支越短，表示合并的簇彼此间较为相似。

确认簇的数量：通过树状图，可以基于树的高度来选择簇的数量。可以设置高度作为阈值，以限制聚类结果。

树状图可视化：代码通过调用plt.show()来可视化展现树状图。这样可以直观地理解层次聚类的结果以及图像间的相似性。

## Adaboost（传统方法）
AdaBoost是Adaptive+Boosting的组合词。

算法的定义如下：
弱分类器（weak classifier）通过顺序（sequential）学习相互补充，并将它们组合在一起以最终提高强分类器（strong classifier）的性能。

工作原理如下：
弱分类器（weak classifier）一次一个地顺序进行学习。首先学习的分类器会产生正确分类的数据和错误分类的数据。首先学习的分类器将正确分类的结果信息和错误分类的结果信息传递给下一分类器。下一分类器利用从前一个分类器接收到的信息来提高分类不佳的数据的权重（weight）。也就是说,通过不断调整前一个分类器错误分类样本的权重，使其更集中于错误分类的数据，从而使学习效果更好。因此，名称中带有“adaptive”。最终分类器（strong classifier）通过对先前学习的弱分类器分别应用权重并进行组合来进行学习。

总结一下，就是将预测性能较低的弱分类器组合在一起，最终形成一个性能稍好一些的强分类器。弱分类器通过相互补充（adaptive）的方式进行学习，并通过组合这些弱分类器来形成一个分类器，因此称为 boosting。

用公式表示如下：
![image](https://github.com/MengYueqi/2023HIT_TOC_Image_Identification/assets/93073249/754561b1-6c6a-4106-9946-a1b411bc014b)

- H(x)：最终强分类器，也称为加权多数投票分类器。
- h：弱分类器，也称为基分类器。
- α：弱分类器的权重，用于衡量弱分类器对最终分类器的重要性。
- t：迭代次数，表示弱分类器的数量。

具体来说：
- H(x)表示最终强分类器对输入样本 x 的预测结果。
- h表示第 t 个弱分类器对输入样本 x 的预测结果。
- α表示第 t 个弱分类器的权重。
- t表示 AdaBoost 算法迭代的次数，即训练的弱分类器的数量。

具体来说，AdaBoost 算法的工作原理如下：
1. 初始化训练数据集的每个样本的权重为 1/N，其中 N 是训练数据集的样本数。
2. 训练一个弱分类器。
3. 计算弱分类器的错误分类率。
4. 将错误分类率高的样本的权重增加，将错误分类率低的样本的权重减少。
5. 重复步骤 2-4，直到满足某个终止条件。
6. 将所有弱分类器的输出通过加权求和得到最终的强分类器的输出。

AdaBoost 算法是提升算法（boosting algorithm）的一种，具有以下优点：
- 可以有效地提高弱分类器的性能。
- 可以处理异常值。
- 可以处理不平衡数据集。
- AdaBoost 算法在分类、回归、异常检测等领域都有广泛应用。

- 训练结果如下：
![FE3851AE084695868C7F9F9AE04B851D](https://github.com/MengYueqi/2023HIT_TOC_Image_Identification/assets/93073249/4cbffa7d-e86d-41ff-a451-bd55e0597394)



## 使用深度学习方法进行识别
在AlexNet出现后，深度学习成为识别图像的一种主要方法。近年来有很多识别图像的深度学习模型。使用多种不同规模、不同原理的模型，对图像进行识别。分析模型的原理，并比较不同模型的准确度差别，以及神经网络模型的优势。

> 大家对完成的模型的效果进行量化分析，并画一些简单的图进行分析。最好提取出识别失败的图像，分析一下失败的原因。分析的内容大家写到readme文件中，画的图和相关模型的代码直接push到相关的文件夹内即可。

### AlexNet模型

#### AlexNet 是一个深度卷积神经网络，它的结构如下：
1. 输入层：
   - 输入图像的尺寸为 227x227x3
2. 第一层（C1）：
   - 卷积层：使用 96 个 11x11 的卷积核，步长为 4，用 2 填充。
   - 激活函数：ReLU
   - 局部相应归一化（LRN）
   - 最大池化：使用 3x3 的核，步长为 2
3. 第二层（C2）：
   - 卷积层：使用 256 个 5x5 的卷积核，步长为 1，用 2 填充。
   - 激活函数：ReLU
   - 局部相应归一化（LRN）
   - 最大池化：使用 3x3 的核，步长为 2
4. 第三层（C3）：
   - 卷积层：使用 384 个 3x3 的卷积核，步长为 1，用 1 填充。
   - 激活函数：ReLU
5. 第四层（C4）：
   - 卷积层：使用 384 个 3x3 的卷积核，步长为 1，用 1 填充。
   - 激活函数：ReLU
6. 第五层（C5）：
   - 卷积层：使用 256 个 3x3 的卷积核，步长为 1，用 1 填充。
   - 激活函数：ReLU
   - 最大池化：使用 3x3 的核，步长为 2
7. 第六层（F6）：
   - 全连接层：有 4096 个神经元
   - 激活函数：ReLU
   - Dropout：为了减少过拟合，训练时随机丢弃一半的神经元
8. 第七层（F7）：
   - 全连接层：有 4096 个神经元
   - 激活函数：ReLU
   - Dropout：为了减少过拟合，训练时随机丢弃一半的神经元
9. 输出层（F8）：
   - 全连接层：有 9 个神经元，对应于数据集的 9 个类别
   - 激活函数：Softmax，用于分类概率输出

#### AlexNet 主要特点：
1. 更深的网络结构：AlexNet由 5 个卷积层、3 个全连接层和最后的 Softmax 分类层组成。
2. ReLU 激活函数：AlexNet 是第一个大规模使用 ReLU 作为激活函数的网络，这加速了训练过程。
3. Dropout：为了减少过拟合，AlexNet 在全连接层中使用了 Dropout。
4. 局部响应归一化（LRN）：在某些卷积层后使用了局部响应归一化。
5. 数据增强：为了进一步减少过拟合，AlexNet 使用了图像平移、翻转和颜色变化等数据增强技术。

#### 训练结果如下：
![graph](./AlexNet/AlexNet.png)
在训练过程中，我们将数据集按 7：3 的比例划分为训练集和测试集。采用 AlexNet 进行训练，训练 50 轮后，发现模型对于测试集的预测准确率不断上升，最后趋于稳定，稳定在 55% 左右；损失函数值也在不断下降，最终达到了 0.13。考虑到样本集中的数据量只有 2700 左右，数据量偏少，因此训练效果不是很理想。如果增大样本集规模，模型预测的准确率应该会有进一步提升。
在训练过程中发现，虽然损失函数值在下降，但是预测准确率却并未上升，有时甚至下降，这说明模型可能存在过拟合现象，这也可能是导致模型预测准确率不高的原因之一。

### YOLO模型

#### YOLOv8的改动

1. 提供了一个全新的 SOTA 模型，包括 P5 640 和 P6 1280 分辨率的目标检测网络和基于 YOLACT 的实例分割模型。和 YOLOv5 一样，基于缩放系数也提供了 N/S/M/L/X 尺度的不同大小模型，用于满足不同场景需求
2. 骨干网络和 Neck 部分可能参考了 YOLOv7 ELAN 设计思想，将 YOLOv5 的 C3 结构换成了梯度流更丰富的 C2f 结构，并对不同尺度模型调整了不同的通道数，属于对模型结构精心微调，不再是无脑一套参数应用所有模型，大幅提升了模型性能。不过这个 C2f 模块中存在 Split 等操作对特定硬件部署没有之前那么友好了
3. Head 部分相比 YOLOv5 改动较大，换成了目前主流的解耦头结构，将分类和检测头分离，同时也从 Anchor-Based 换成了 Anchor-Free
4. Loss 计算方面采用了 TaskAlignedAssigner 正样本分配策略，并引入了 Distribution Focal Loss
5. 训练的数据增强部分引入了 YOLOX 中的最后 10 epoch 关闭 Mosiac 增强的操作，可以有效地提升精度

![img.png](YOLO/pics/img.png)

#### YOLO的架构

YOLO的架构如下图所示
![img.png](YOLO/pics/img1.png)

#### YOLO的原理

1. 特征提取：YOLOv8使用深度CNN模型来提取图像特征。
2. 划分网格：YOLOv8将输入的图片分割成 SxS 网格。每个单元格负责去检测那些中心点落在该格子内的目标。
3. 预测边界框与类别：每个单元格会预测 B 个边界框（bounding box）以及边界框的置信度（confidence score）。置信度其实包含两个方面，一是这个边界框含有目标的可能性大小，二是这个边界框的准确度。边界框的大小与位置可以用4个值来表征： (x, y,w,h)，其中 (x,y) 是边界框的中心坐标，而 w 和 h 是边界框的宽与高。
4. 特征金字塔网络：该模型利用特征金字塔网络来检测图像中不同大小和比例的对象。这个特征金字塔网络由多个层组成，这些层在不同的比例上检测对象，使得模型能够在图像中检测到大和小的对象。
5. 后处理：最后处理网络预测结果得到最终的目标检测结果。

#### 结果分析

- YOLO模型在10轮训练后，LOSS率降至最低，20轮后基本稳定。
- YOLO模型同时能够达到较高的准确度，在6轮后准确率基本超过95%。

![result](YOLO/runs/classify/train2/results.png)


### Vision Transformer(ViT)模型

